# Production Fluentd Aggregator Deployment
# Enterprise EFK Architecture: FluentBit (DaemonSet) → Fluentd (Deployment) → Elasticsearch
# Based on picluster.ricsanfre.com - Used by Google, Microsoft, Netflix

# Deploy as Deployment with 2 replicas (NOT DaemonSet)
kind: "Deployment"
replicaCount: 2

# Use custom aggregator image optimized for Deployment mode
image:
  repository: ricsanfre/fluentd-aggregator
  tag: "v1.17.1-debian-1.0"

# Environment variables for Elasticsearch connection
env:
  - name: FLUENT_ELASTICSEARCH_HOST
    value: "production-cluster-es-http.elastic-system"
  - name: FLUENT_ELASTICSEARCH_PORT  
    value: "9200"
  - name: FLUENT_ELASTICSEARCH_SCHEME
    value: "https"
  - name: FLUENT_ELASTICSEARCH_SSL_VERIFY
    value: "false"
  - name: FLUENT_ELASTICSEARCH_USER
    value: "elastic"
  - name: FLUENT_ELASTICSEARCH_PASSWORD
    valueFrom:
      secretKeyRef:
        name: production-cluster-es-elastic-user
        key: elastic

# Production resource limits for aggregator workload
resources:
  limits:
    cpu: 500m
    memory: 1Gi
  requests:
    cpu: 200m
    memory: 512Mi

# ClusterIP service for FluentBit → Fluentd communication
service:
  enabled: true
  type: ClusterIP
  ports:
    - name: forwarder
      protocol: TCP
      containerPort: 24224

# No additional plugins needed (included in custom image)
plugins: []

# Pure aggregator configuration - NO kubernetes_metadata filter!
# FluentBit already enriched logs with K8s metadata
fileConfigs:
  01_sources.conf: |-
    # Receive forwarded logs from FluentBit DaemonSet
    <source>
      @type forward
      port 24224
      bind 0.0.0.0
    </source>
    
  02_filters.conf: |-
    # Optional: Add aggregator hostname for troubleshooting
    <filter **>
      @type record_transformer
      <record>
        fluentd_aggregator "#{Socket.gethostname}"
      </record>
    </filter>
    
  04_outputs.conf: |-
    # @OUTPUT label for relabeled traffic from dispatcher
    <label @OUTPUT>
      <match **>
        @type elasticsearch
        host "#{ENV['FLUENT_ELASTICSEARCH_HOST']}"
        port "#{ENV['FLUENT_ELASTICSEARCH_PORT']}"
        scheme "#{ENV['FLUENT_ELASTICSEARCH_SCHEME']}"
        ssl_verify "#{ENV['FLUENT_ELASTICSEARCH_SSL_VERIFY']}"
        user "#{ENV['FLUENT_ELASTICSEARCH_USER']}"
        password "#{ENV['FLUENT_ELASTICSEARCH_PASSWORD']}"
        logstash_format true
        logstash_prefix homelab-k8s
        include_tag_key true
        tag_key @log_name
        <buffer>
          @type file
          path /buffers/fluentd-buffers
          flush_mode interval
          flush_interval 5s
          retry_forever true
          retry_max_interval 30
          chunk_limit_size 2M
          total_limit_size 500M
          overflow_action block
        </buffer>
      </match>
    </label>

# Persistent buffer storage
volumeMounts:
  - name: buffer-storage
    mountPath: /buffers

volumes:
  - name: buffer-storage
    emptyDir: {}

# CRITICAL: Disable K8s API access (aggregator doesn't need it)
serviceAccount:
  create: false
rbac:
  create: false

# Non-root security context
securityContext:
  runAsNonRoot: true
  runAsUser: 1000

# Aggregator doesn't access host filesystem
mountVarLogDirectory: false
mountDockerContainersDirectory: false

# Health checks - use TCP socket on forward input port
readinessProbe:
  tcpSocket:
    port: 24224
  initialDelaySeconds: 10
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

livenessProbe:
  tcpSocket:
    port: 24224
  initialDelaySeconds: 30
  periodSeconds: 30
  timeoutSeconds: 5
  failureThreshold: 3

# Disable monitoring until metrics endpoint is available
serviceMonitor:
  enabled: false