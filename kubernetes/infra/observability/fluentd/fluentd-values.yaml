# Fluentd deployment as aggregator (receives from FluentBit)
# CRITICAL: Force deployment mode (not daemonset)
kind: Deployment
replicaCount: 2

# Official Fluentd image for deployment (not daemonset)
image:
  repository: fluent/fluentd
  tag: "v1.17-debian-1"

# Custom Fluentd configuration for log aggregation
fluentdConf: |
  # Input: Receive logs from FluentBit via forward protocol
  <source>
    @type forward
    @id input_forward
    port 24224
    bind 0.0.0.0
  </source>

  # Output: Send aggregated logs to Elasticsearch
  <match **>
    @type elasticsearch
    @id out_es
    @log_level info
    include_tag_key true
    
    # Elasticsearch connection
    host production-cluster-es-http.elastic-system
    port 9200
    scheme https
    ssl_verify false
    
    # Authentication
    user elastic
    password "#{ENV['ELASTICSEARCH_PASSWORD']}"
    
    # Index configuration
    index_name logs
    type_name _doc
    
    # Buffering and performance
    <buffer>
      @type file
      path /opt/bitnami/fluentd/logs/buffers/logs.buffer
      flush_mode interval
      retry_type exponential_backoff
      flush_thread_count 2
      flush_interval 5s
      retry_forever
      retry_max_interval 30
      chunk_limit_size 2M
      total_limit_size 500M
      overflow_action block
    </buffer>
  </match>

# Environment variables for Elasticsearch password
env:
  - name: ELASTICSEARCH_PASSWORD
    valueFrom:
      secretKeyRef:
        name: production-cluster-es-elastic-user
        key: elastic

# Resource limits for aggregator deployment
resources:
  limits:
    cpu: 200m
    memory: 512Mi
  requests:
    cpu: 100m
    memory: 256Mi

# Service for FluentBit to send logs to Fluentd
service:
  type: ClusterIP
  
# ServiceMonitor for Prometheus
serviceMonitor:
  enabled: true

# Deployment specific settings (not DaemonSet)
replicaCount: 2
autoscaling:
  enabled: false