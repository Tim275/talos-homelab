# Production Fluentd Aggregator Deployment
# Enterprise EFK Architecture: FluentBit (DaemonSet) → Fluentd (Deployment) → Elasticsearch
# Based on picluster.ricsanfre.com - Used by Google, Microsoft, Netflix

# Deploy as Deployment with 1 replica for homelab (NOT DaemonSet)
kind: "Deployment"
replicaCount: 1

# Use official Fluentd image with Elasticsearch plugin
image:
  repository: fluent/fluentd-kubernetes-daemonset
  tag: "v1.17-debian-elasticsearch8-1"

# Environment variables for Elasticsearch connection
env:
  - name: FLUENT_ELASTICSEARCH_HOST
    value: "production-cluster-es-http.elastic-system"
  - name: FLUENT_ELASTICSEARCH_PORT  
    value: "9200"
  - name: FLUENT_ELASTICSEARCH_SCHEME
    value: "https"
  - name: FLUENT_ELASTICSEARCH_SSL_VERIFY
    value: "false"
  - name: FLUENT_ELASTICSEARCH_USER
    value: "elastic"
  - name: FLUENT_ELASTICSEARCH_PASSWORD
    valueFrom:
      secretKeyRef:
        name: production-cluster-es-elastic-user
        key: elastic

# Production resource limits for aggregator workload
resources:
  limits:
    cpu: 500m
    memory: 1Gi
  requests:
    cpu: 200m
    memory: 512Mi

# ClusterIP service for FluentBit → Fluentd communication
service:
  enabled: true
  type: ClusterIP
  ports:
    - name: forwarder
      protocol: TCP
      containerPort: 24224

# No additional plugins needed (included in custom image)
plugins: []

# Pure aggregator configuration - NO kubernetes_metadata filter!
# FluentBit already enriched logs with K8s metadata
fileConfigs:
  01_sources.conf: |-
    # Receive forwarded logs from FluentBit DaemonSet
    <source>
      @type forward
      port 24224
      bind 0.0.0.0
    </source>
    
  02_filters.conf: |-
    # Optional: Add aggregator hostname for troubleshooting
    <filter **>
      @type record_transformer
      <record>
        fluentd_aggregator "#{Socket.gethostname}"
      </record>
    </filter>
    
  04_outputs.conf: |-
    # Direct Elasticsearch output (simple aggregator config)
    <match **>
      @type elasticsearch
      host "#{ENV['FLUENT_ELASTICSEARCH_HOST']}"
      port "#{ENV['FLUENT_ELASTICSEARCH_PORT']}"
      scheme "#{ENV['FLUENT_ELASTICSEARCH_SCHEME']}"
      ssl_verify "#{ENV['FLUENT_ELASTICSEARCH_SSL_VERIFY']}"
      user "#{ENV['FLUENT_ELASTICSEARCH_USER']}"
      password "#{ENV['FLUENT_ELASTICSEARCH_PASSWORD']}"
      logstash_format true
      logstash_prefix homelab-k8s
      include_tag_key true
      tag_key @log_name
      <buffer>
        @type file
        path /buffers/fluentd-buffers
        flush_mode interval
        flush_interval 5s
        retry_forever true
        retry_max_interval 30
        chunk_limit_size 2M
        total_limit_size 500M
        overflow_action block
      </buffer>
    </match>

# Persistent buffer storage
volumeMounts:
  - name: buffer-storage
    mountPath: /buffers

volumes:
  - name: buffer-storage
    emptyDir: {}

# CRITICAL: Disable K8s API access (aggregator doesn't need it)
serviceAccount:
  create: false
rbac:
  create: false

# Non-root security context
securityContext:
  runAsNonRoot: true
  runAsUser: 1000

# Aggregator doesn't access host filesystem
mountVarLogDirectory: false
mountDockerContainersDirectory: false

# Disable health checks completely - metrics endpoint not available  
readinessProbe: {}
livenessProbe: {}

# Disable monitoring until metrics endpoint is available
serviceMonitor:
  enabled: false