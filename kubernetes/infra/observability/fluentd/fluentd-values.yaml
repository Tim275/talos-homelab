# Production Fluentd Aggregator Deployment
# Enterprise EFK Architecture: FluentBit (DaemonSet) → Fluentd (Deployment) → Elasticsearch
# Based on picluster.ricsanfre.com - Used by Google, Microsoft, Netflix

# Deploy as Deployment with 2 replicas (NOT DaemonSet)
kind: "Deployment"
replicaCount: 2

# Use official Fluentd image with Elasticsearch plugin
image:
  repository: fluent/fluentd-kubernetes-daemonset
  tag: "v1.17-debian-elasticsearch8-1"

# Environment variables for Elasticsearch connection
env:
  - name: FLUENT_ELASTICSEARCH_HOST
    value: "production-cluster-es-http.elastic-system"
  - name: FLUENT_ELASTICSEARCH_PORT  
    value: "9200"
  - name: FLUENT_ELASTICSEARCH_SCHEME
    value: "https"
  - name: FLUENT_ELASTICSEARCH_SSL_VERIFY
    value: "false"
  - name: FLUENT_ELASTICSEARCH_USER
    value: "elastic"
  - name: FLUENT_ELASTICSEARCH_PASSWORD
    valueFrom:
      secretKeyRef:
        name: production-cluster-es-elastic-user
        key: elastic

# Production resource limits for aggregator workload
resources:
  limits:
    cpu: 500m
    memory: 1Gi
  requests:
    cpu: 200m
    memory: 512Mi

# ClusterIP service for FluentBit → Fluentd communication
service:
  enabled: true
  type: ClusterIP
  ports:
    - name: forwarder
      protocol: TCP
      containerPort: 24224

# No additional plugins needed (included in custom image)
plugins: []

# Pure aggregator configuration - NO kubernetes_metadata filter!
# FluentBit already enriched logs with K8s metadata
fileConfigs:
  01_sources.conf: |-
    # Receive forwarded logs from FluentBit DaemonSet
    <source>
      @type forward
      port 24224
      bind 0.0.0.0
    </source>
    
  02_filters.conf: |-
    # Optional: Add aggregator hostname for troubleshooting
    <filter **>
      @type record_transformer
      <record>
        fluentd_aggregator "#{Socket.gethostname}"
      </record>
    </filter>

  03_dispatch.conf: |-
    # Route all filtered logs to @DISPATCH label for processing
    <match **>
      @type relabel
      @label @DISPATCH
    </match>
    
  04_outputs.conf: |-
    # @OUTPUT label for relabeled traffic from dispatcher
    <label @OUTPUT>
      <match **>
        @type elasticsearch
        host "#{ENV['FLUENT_ELASTICSEARCH_HOST']}"
        port "#{ENV['FLUENT_ELASTICSEARCH_PORT']}"
        scheme "#{ENV['FLUENT_ELASTICSEARCH_SCHEME']}"
        ssl_verify "#{ENV['FLUENT_ELASTICSEARCH_SSL_VERIFY']}"
        user "#{ENV['FLUENT_ELASTICSEARCH_USER']}"
        password "#{ENV['FLUENT_ELASTICSEARCH_PASSWORD']}"
        logstash_format true
        logstash_prefix homelab-k8s
        include_tag_key true
        tag_key @log_name
        <buffer>
          @type file
          path /buffers/fluentd-buffers
          flush_mode interval
          flush_interval 5s
          retry_forever true
          retry_max_interval 30
          chunk_limit_size 2M
          total_limit_size 500M
          overflow_action block
        </buffer>
      </match>
    </label>

# Persistent buffer storage
volumeMounts:
  - name: buffer-storage
    mountPath: /buffers

volumes:
  - name: buffer-storage
    emptyDir: {}

# CRITICAL: Disable K8s API access (aggregator doesn't need it)
serviceAccount:
  create: false
rbac:
  create: false

# Non-root security context
securityContext:
  runAsNonRoot: true
  runAsUser: 1000

# Aggregator doesn't access host filesystem
mountVarLogDirectory: false
mountDockerContainersDirectory: false

# Disable health checks completely - metrics endpoint not available  
readinessProbe: {}
livenessProbe: {}

# Disable monitoring until metrics endpoint is available
serviceMonitor:
  enabled: false