# Working Fluentd Configuration based on DevOps Blog Example
# This bypasses broken Helm chart environment variable handling

# Deploy as Deployment, not DaemonSet
kind: "Deployment"
replicaCount: 1

# Use working Fluentd image
image:
  repository: "fluent/fluentd-kubernetes-daemonset"
  tag: "v1-debian-elasticsearch"

# Service for FluentBit forwarding - using port 24224
service:
  type: "ClusterIP"
  ports:
    - name: "forward"
      protocol: TCP
      containerPort: 24224
      servicePort: 24224

# Resource limits
resources:
  limits:
    memory: "1Gi"
    cpu: "500m"
  requests:
    memory: "512Mi" 
    cpu: "200m"

# RBAC
rbac:
  create: true

serviceAccount:
  create: true

# CRITICAL: Disable default configs and use our own
defaultConfigs:
  enabled: false

# SECURE DUAL-INDEX FLUENTD CONFIG FOR TALOS
# FluentBit -> Fluentd -> Elasticsearch -> Kibana
# kube.* tags -> kubernetes-logs-YYYY.MM.DD 
# host.* tags -> talos-logs-YYYY.MM.DD

# Environment variables from Kubernetes Secret for security
env:
  - name: ELASTICSEARCH_HOST
    valueFrom:
      secretKeyRef:
        name: elasticsearch-credentials
        key: ELASTICSEARCH_HOST
  - name: ELASTICSEARCH_PORT
    valueFrom:
      secretKeyRef:
        name: elasticsearch-credentials
        key: ELASTICSEARCH_PORT
  - name: ELASTICSEARCH_SCHEME
    valueFrom:
      secretKeyRef:
        name: elasticsearch-credentials
        key: ELASTICSEARCH_SCHEME
  - name: ELASTICSEARCH_SSL_VERIFY
    valueFrom:
      secretKeyRef:
        name: elasticsearch-credentials
        key: ELASTICSEARCH_SSL_VERIFY
  - name: ELASTICSEARCH_USERNAME
    valueFrom:
      secretKeyRef:
        name: elasticsearch-credentials
        key: ELASTICSEARCH_USERNAME
  - name: ELASTICSEARCH_PASSWORD
    valueFrom:
      secretKeyRef:
        name: elasticsearch-credentials
        key: ELASTICSEARCH_PASSWORD

fileConfigs:
  01_sources.conf: |-
    # Ignore Fluentd's own logs to prevent recursion
    <match fluent.**>
      @type null
    </match>
    
    # Input: Forward protocol from FluentBit
    <source>
      @type forward
      port 24224
      bind 0.0.0.0
    </source>

  02_filters.conf: |-
    # No additional filters needed - FluentBit handles all filtering

  03_outputs.conf: |-
    # MICROSERVICE-AWARE INDEX ROUTING STRATEGY
    # Route logs to dedicated indices based on namespace/service type
    
    # Route 1: Infrastructure Services (GitOps, Secrets, Storage, Databases)
    <match kube.var.log.containers.**_argocd_** kube.var.log.containers.**_cert-manager_** kube.var.log.containers.**_sealed-secrets_** kube.var.log.containers.**_cnpg-system_** kube.var.log.containers.**_rook-ceph_**>
      @type elasticsearch
      @log_level info
      include_tag_key true
      host "#{ENV['ELASTICSEARCH_HOST']}"
      port "#{ENV['ELASTICSEARCH_PORT']}"
      scheme "#{ENV['ELASTICSEARCH_SCHEME']}"
      ssl_verify "#{ENV['ELASTICSEARCH_SSL_VERIFY']}"
      user "#{ENV['ELASTICSEARCH_USERNAME']}"
      password "#{ENV['ELASTICSEARCH_PASSWORD']}"
      reload_connections false
      reconnect_on_error true
      reload_on_failure true
      logstash_format false
      index_name infrastructure-logs
      <buffer>
        @type file
        path /var/log/fluentd-buffers/infrastructure.buffer
        flush_mode interval
        flush_interval 5s
        chunk_limit_size 2M
        total_limit_size 1G
        overflow_action block
        retry_forever true
        retry_max_interval 30
      </buffer>
    </match>
    
    # Route 2: Monitoring & Observability Stack
    <match kube.var.log.containers.**_monitoring_** kube.var.log.containers.**_elastic-system_** kube.var.log.containers.**_observability_**>
      @type elasticsearch
      @log_level info
      include_tag_key true
      host "#{ENV['ELASTICSEARCH_HOST']}"
      port "#{ENV['ELASTICSEARCH_PORT']}"
      scheme "#{ENV['ELASTICSEARCH_SCHEME']}"
      ssl_verify "#{ENV['ELASTICSEARCH_SSL_VERIFY']}"
      user "#{ENV['ELASTICSEARCH_USERNAME']}"
      password "#{ENV['ELASTICSEARCH_PASSWORD']}"
      reload_connections false
      reconnect_on_error true
      reload_on_failure true
      logstash_format false
      index_name monitoring-logs
      <buffer>
        @type file
        path /var/log/fluentd-buffers/monitoring.buffer
        flush_mode interval
        flush_interval 5s
        chunk_limit_size 2M
        total_limit_size 1G
        overflow_action block
        retry_forever true
        retry_max_interval 30
      </buffer>
    </match>
    
    # Route 3: Development Applications
    <match kube.var.log.containers.**_n8n-dev_** kube.var.log.containers.**_audiobookshelf-dev_** kube.var.log.containers.**_*-dev_**>
      @type elasticsearch
      @log_level info
      include_tag_key true
      host "#{ENV['ELASTICSEARCH_HOST']}"
      port "#{ENV['ELASTICSEARCH_PORT']}"
      scheme "#{ENV['ELASTICSEARCH_SCHEME']}"
      ssl_verify "#{ENV['ELASTICSEARCH_SSL_VERIFY']}"
      user "#{ENV['ELASTICSEARCH_USERNAME']}"
      password "#{ENV['ELASTICSEARCH_PASSWORD']}"
      reload_connections false
      reconnect_on_error true
      reload_on_failure true
      logstash_format false
      index_name applications-dev-logs
      <buffer>
        @type file
        path /var/log/fluentd-buffers/applications-dev.buffer
        flush_mode interval
        flush_interval 5s
        chunk_limit_size 2M
        total_limit_size 1G
        overflow_action block
        retry_forever true
        retry_max_interval 30
      </buffer>
    </match>
    
    # Route 4: Production Applications
    <match kube.var.log.containers.**_n8n-prod_** kube.var.log.containers.**_audiobookshelf-prod_** kube.var.log.containers.**_*-prod_**>
      @type elasticsearch
      @log_level info
      include_tag_key true
      host "#{ENV['ELASTICSEARCH_HOST']}"
      port "#{ENV['ELASTICSEARCH_PORT']}"
      scheme "#{ENV['ELASTICSEARCH_SCHEME']}"
      ssl_verify "#{ENV['ELASTICSEARCH_SSL_VERIFY']}"
      user "#{ENV['ELASTICSEARCH_USERNAME']}"
      password "#{ENV['ELASTICSEARCH_PASSWORD']}"
      reload_connections false
      reconnect_on_error true
      reload_on_failure true
      logstash_format false
      index_name applications-prod-logs
      <buffer>
        @type file
        path /var/log/fluentd-buffers/applications-prod.buffer
        flush_mode interval
        flush_interval 5s
        chunk_limit_size 2M
        total_limit_size 1G
        overflow_action block
        retry_forever true
        retry_max_interval 30
      </buffer>
    </match>
    
    # Route 5: Platform Services (Kafka, Cloudflared, etc.)
    <match kube.var.log.containers.**_kafka_** kube.var.log.containers.**_cloudflared_** kube.var.log.containers.**_cloudbeaver_** kube.var.log.containers.**_gateway_**>
      @type elasticsearch
      @log_level info
      include_tag_key true
      host "#{ENV['ELASTICSEARCH_HOST']}"
      port "#{ENV['ELASTICSEARCH_PORT']}"
      scheme "#{ENV['ELASTICSEARCH_SCHEME']}"
      ssl_verify "#{ENV['ELASTICSEARCH_SSL_VERIFY']}"
      user "#{ENV['ELASTICSEARCH_USERNAME']}"
      password "#{ENV['ELASTICSEARCH_PASSWORD']}"
      reload_connections false
      reconnect_on_error true
      reload_on_failure true
      logstash_format false
      index_name platform-logs
      <buffer>
        @type file
        path /var/log/fluentd-buffers/platform.buffer
        flush_mode interval
        flush_interval 5s
        chunk_limit_size 2M
        total_limit_size 1G
        overflow_action block
        retry_forever true
        retry_max_interval 30
      </buffer>
    </match>
    
    # Route 6: Catch-all for any remaining Kubernetes logs
    <match kube.**>
      @type elasticsearch
      @log_level info
      include_tag_key true
      host "#{ENV['ELASTICSEARCH_HOST']}"
      port "#{ENV['ELASTICSEARCH_PORT']}"
      scheme "#{ENV['ELASTICSEARCH_SCHEME']}"
      ssl_verify "#{ENV['ELASTICSEARCH_SSL_VERIFY']}"
      user "#{ENV['ELASTICSEARCH_USERNAME']}"
      password "#{ENV['ELASTICSEARCH_PASSWORD']}"
      reload_connections false
      reconnect_on_error true
      reload_on_failure true
      logstash_format false
      index_name kubernetes-other-logs
      <buffer>
        @type file
        path /var/log/fluentd-buffers/kubernetes-other.buffer
        flush_mode interval
        flush_interval 5s
        chunk_limit_size 2M
        total_limit_size 1G
        overflow_action block
        retry_forever true
        retry_max_interval 30
      </buffer>
    </match>
    
    # Route 2: ALL Talos Host System logs (host.* tags) -> talos-logs-*
    <match host.**>
      @type elasticsearch
      @log_level info
      include_tag_key true
      host "#{ENV['ELASTICSEARCH_HOST']}"
      port "#{ENV['ELASTICSEARCH_PORT']}"
      scheme "#{ENV['ELASTICSEARCH_SCHEME']}"
      ssl_verify "#{ENV['ELASTICSEARCH_SSL_VERIFY']}"
      user "#{ENV['ELASTICSEARCH_USERNAME']}"
      password "#{ENV['ELASTICSEARCH_PASSWORD']}"
      reload_connections false
      reconnect_on_error true
      reload_on_failure true
      # TALOS HOST LOGS INDEX - Monthly rotation for system logs
      logstash_prefix talos-logs
      logstash_dateformat %Y.%m
      logstash_format true
      <buffer>
        @type file
        path /var/log/fluentd-buffers/talos.buffer
        flush_mode interval
        flush_interval 5s
        chunk_limit_size 2M
        total_limit_size 1G
        overflow_action block
        retry_forever true
        retry_max_interval 30
      </buffer>
    </match>