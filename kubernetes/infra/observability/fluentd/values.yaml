# Working Fluentd Configuration based on DevOps Blog Example
# This bypasses broken Helm chart environment variable handling

# Deploy as Deployment, not DaemonSet
kind: "Deployment"
replicaCount: 1

# Use working Fluentd image
image:
  repository: "fluent/fluentd-kubernetes-daemonset"
  tag: "v1-debian-elasticsearch"

# Service for FluentBit forwarding - using port 24224
service:
  type: "ClusterIP"
  ports:
    - name: "forward"
      protocol: TCP
      containerPort: 24224
      servicePort: 24224

# Resource limits
resources:
  limits:
    memory: "1Gi"
    cpu: "500m"
  requests:
    memory: "512Mi" 
    cpu: "200m"

# RBAC
rbac:
  create: true

serviceAccount:
  create: true

# CRITICAL: Disable default configs and use our own
defaultConfigs:
  enabled: false

# SECURE DUAL-INDEX FLUENTD CONFIG FOR TALOS
# FluentBit -> Fluentd -> Elasticsearch -> Kibana
# kube.* tags -> kubernetes-logs-YYYY.MM.DD 
# host.* tags -> talos-logs-YYYY.MM.DD

# Environment variables for security
env:
  - name: ELASTICSEARCH_HOST
    value: "production-cluster-es-http.elastic-system"
  - name: ELASTICSEARCH_PORT
    value: "9200"
  - name: ELASTICSEARCH_SCHEME
    value: "https"
  - name: ELASTICSEARCH_SSL_VERIFY
    value: "false"
  - name: ELASTICSEARCH_USERNAME
    value: "elastic"
  - name: ELASTICSEARCH_PASSWORD
    value: "04h26K03zEMhI7I9DRbk5AT5"

fileConfigs:
  01_sources.conf: |-
    # Ignore Fluentd's own logs to prevent recursion
    <match fluent.**>
      @type null
    </match>
    
    # Input: Forward protocol from FluentBit
    <source>
      @type forward
      port 24224
      bind 0.0.0.0
    </source>

  02_filters.conf: |-
    # No additional filters needed - FluentBit handles all filtering

  03_outputs.conf: |-
    # Route 1: ALL Kubernetes logs (kube.* tags) -> kubernetes-logs-*
    <match kube.**>
      @type elasticsearch
      @log_level info
      include_tag_key true
      host "#{ENV['ELASTICSEARCH_HOST']}"
      port "#{ENV['ELASTICSEARCH_PORT']}"
      scheme "#{ENV['ELASTICSEARCH_SCHEME']}"
      ssl_verify "#{ENV['ELASTICSEARCH_SSL_VERIFY']}"
      user "#{ENV['ELASTICSEARCH_USERNAME']}"
      password "#{ENV['ELASTICSEARCH_PASSWORD']}"
      reload_connections false
      reconnect_on_error true
      reload_on_failure true
      # KUBERNETES LOGS INDEX
      logstash_prefix kubernetes-logs
      logstash_dateformat %Y.%m.%d
      logstash_format true
      <buffer>
        @type file
        path /var/log/fluentd-buffers/kubernetes.buffer
        flush_mode interval
        flush_interval 5s
        chunk_limit_size 2M
        total_limit_size 1G
        overflow_action block
        retry_forever true
        retry_max_interval 30
      </buffer>
    </match>
    
    # Route 2: ALL Talos Host System logs (host.* tags) -> talos-logs-*
    <match host.**>
      @type elasticsearch
      @log_level info
      include_tag_key true
      host "#{ENV['ELASTICSEARCH_HOST']}"
      port "#{ENV['ELASTICSEARCH_PORT']}"
      scheme "#{ENV['ELASTICSEARCH_SCHEME']}"
      ssl_verify "#{ENV['ELASTICSEARCH_SSL_VERIFY']}"
      user "#{ENV['ELASTICSEARCH_USERNAME']}"
      password "#{ENV['ELASTICSEARCH_PASSWORD']}"
      reload_connections false
      reconnect_on_error true
      reload_on_failure true
      # TALOS HOST LOGS INDEX
      logstash_prefix talos-logs
      logstash_dateformat %Y.%m.%d
      logstash_format true
      <buffer>
        @type file
        path /var/log/fluentd-buffers/talos.buffer
        flush_mode interval
        flush_interval 5s
        chunk_limit_size 2M
        total_limit_size 1G
        overflow_action block
        retry_forever true
        retry_max_interval 30
      </buffer>
    </match>