---
# Enterprise Ceph Monitoring ServiceMonitor
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: rook-ceph-mgr
  namespace: rook-ceph
  labels:
    team: storage
    monitoring: ceph
  annotations:
    argocd.argoproj.io/sync-wave: "4"
spec:
  namespaceSelector:
    matchNames:
      - rook-ceph
  selector:
    matchLabels:
      app: rook-ceph-mgr
      ceph_daemon_type: mgr
  endpoints:
    - port: http-metrics
      path: /metrics
      interval: 30s
      scrapeTimeout: 10s

---
# Ceph Exporter ServiceMonitor
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: rook-ceph-exporter
  namespace: rook-ceph
  labels:
    team: storage
    monitoring: ceph
  annotations:
    argocd.argoproj.io/sync-wave: "4"
spec:
  namespaceSelector:
    matchNames:
      - rook-ceph
  selector:
    matchLabels:
      app: rook-ceph-exporter
  endpoints:
    - port: ceph-exporter-http-metrics
      path: /metrics
      interval: 30s
      scrapeTimeout: 10s

---
# Enterprise Ceph AlertManager Rules
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: rook-ceph-enterprise-alerts
  namespace: rook-ceph
  labels:
    team: storage
    monitoring: ceph
    prometheus: kube-prometheus
    role: alert-rules
  annotations:
    argocd.argoproj.io/sync-wave: "4"
spec:
  groups:
    - name: ceph.storage.rules
      interval: 30s
      rules:
        # Cluster Health Alerts
        - alert: CephClusterCritical
          expr: ceph_health_status == 2
          for: 0m
          labels:
            severity: critical
            service: ceph
            team: storage
          annotations:
            summary: "Ceph cluster is in HEALTH_ERR state"
            description: "Ceph cluster {{ $labels.cluster }} health is HEALTH_ERR. Immediate attention required."
            runbook_url: "https://docs.ceph.com/en/latest/rados/troubleshooting/"

        - alert: CephClusterWarning
          expr: ceph_health_status == 1
          for: 5m
          labels:
            severity: warning
            service: ceph
            team: storage
          annotations:
            summary: "Ceph cluster is in HEALTH_WARN state"
            description: "Ceph cluster {{ $labels.cluster }} health is HEALTH_WARN for more than 5 minutes."

        # OSD Alerts
        - alert: CephOSDDown
          expr: ceph_osd_up == 0
          for: 1m
          labels:
            severity: critical
            service: ceph
            team: storage
          annotations:
            summary: "Ceph OSD is down"
            description: "OSD {{ $labels.osd }} on cluster {{ $labels.cluster }} is down."

        - alert: CephOSDNearFull
          expr: ceph_osd_stat_bytes_used / ceph_osd_stat_bytes > 0.85
          for: 5m
          labels:
            severity: warning
            service: ceph
            team: storage
          annotations:
            summary: "Ceph OSD is near full"
            description: "OSD {{ $labels.osd }} is {{ $value | humanizePercentage }} full."

        - alert: CephOSDFull
          expr: ceph_osd_stat_bytes_used / ceph_osd_stat_bytes > 0.95
          for: 1m
          labels:
            severity: critical
            service: ceph
            team: storage
          annotations:
            summary: "Ceph OSD is full"
            description: "OSD {{ $labels.osd }} is {{ $value | humanizePercentage }} full. Immediate action required."

        # MON Alerts
        - alert: CephMonDown
          expr: ceph_mon_quorum_status == 0
          for: 1m
          labels:
            severity: critical
            service: ceph
            team: storage
          annotations:
            summary: "Ceph monitor is down"
            description: "Monitor {{ $labels.mon }} on cluster {{ $labels.cluster }} is down."

        - alert: CephMonClockSkew
          expr: abs(ceph_mon_clock_skew_seconds) > 0.2
          for: 5m
          labels:
            severity: warning
            service: ceph
            team: storage
          annotations:
            summary: "Ceph monitor clock skew detected"
            description: "Monitor {{ $labels.mon }} has a clock skew of {{ $value }}s."

        # Pool Alerts
        - alert: CephPoolNearFull
          expr: ceph_pool_stored_raw / ceph_pool_max_avail > 0.85
          for: 5m
          labels:
            severity: warning
            service: ceph
            team: storage
          annotations:
            summary: "Ceph pool is near full"
            description: "Pool {{ $labels.pool }} is {{ $value | humanizePercentage }} full."

        # PG Alerts
        - alert: CephPGsInactive
          expr: ceph_pg_total - ceph_pg_active > 0
          for: 5m
          labels:
            severity: warning
            service: ceph
            team: storage
          annotations:
            summary: "Ceph has inactive placement groups"
            description: "{{ $value }} placement groups are inactive on cluster {{ $labels.cluster }}."

        - alert: CephPGsInconsistent
          expr: ceph_pg_inconsistent > 0
          for: 1m
          labels:
            severity: critical
            service: ceph
            team: storage
          annotations:
            summary: "Ceph has inconsistent placement groups"
            description: "{{ $value }} placement groups are inconsistent on cluster {{ $labels.cluster }}."

        # Performance Alerts
        - alert: CephSlowOps
          expr: ceph_osd_op_w_latency_sum / ceph_osd_op_w_latency_count > 1
          for: 5m
          labels:
            severity: warning
            service: ceph
            team: storage
          annotations:
            summary: "Ceph OSD has slow operations"
            description: "OSD {{ $labels.osd }} has average write latency of {{ $value }}s."

---
# Ceph Dashboard Ingress for Enterprise Access
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: rook-ceph-dashboard
  namespace: rook-ceph
  labels:
    app: rook-ceph-dashboard
  annotations:
    argocd.argoproj.io/sync-wave: "4"
    nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    cert-manager.io/cluster-issuer: "letsencrypt-production"
spec:
  tls:
    - hosts:
        - ceph.timour-homelab.com
      secretName: ceph-dashboard-tls
  rules:
    - host: ceph.timour-homelab.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: rook-ceph-mgr-dashboard
                port:
                  number: 8443