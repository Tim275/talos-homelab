# Druid Helm Chart - Minimal Working Config
image:
  repository: apache/druid
  tag: "30.0.1"

# ZooKeeper
zookeeper:
  enabled: true
  replicaCount: 1
  image:
    registry: docker.io
    repository: bitnamilegacy/zookeeper
    tag: "3.8.4-debian-12-r0"
  persistence:
    enabled: true
    storageClass: rook-ceph-block-enterprise
    size: 2Gi

# Disable built-in PostgreSQL (use CNPG)
postgresql:
  enabled: false

# External metadata
metadataStore:
  type: postgresql
  host: druid-postgres-rw.druid.svc
  port: 5432
  user: druid
  password: druid-metadata-2026

# Deep storage - Rook-Ceph S3
deepStorage:
  type: s3

# Extensions - include Kafka + S3 + Prometheus for streaming ingestion
extensions:
  loadList:
    - druid-kafka-indexing-service
    - druid-datasketches
    - druid-multi-stage-query
    - postgresql-metadata-storage
    - druid-s3-extensions
    - prometheus-emitter

# Storage config - S3 via Rook-Ceph
configVars:
  # S3 Deep Storage (Rook-Ceph)
  druid_storage_type: s3
  druid_storage_bucket: druid-segments-3ba7b62e-6999-486f-a26b-7a3a8e95a4a7
  druid_storage_baseKey: segments
  druid_s3_accessKey: "$(AWS_ACCESS_KEY_ID)"
  druid_s3_secretKey: "$(AWS_SECRET_ACCESS_KEY)"
  druid_s3_endpoint_url: "http://rook-ceph-rgw-homelab-objectstore.rook-ceph.svc:80"
  druid_s3_enablePathStyleAccess: "true"
  druid_s3_protocol: "http"
  druid_zk_service_enabled: "true"
  druid_discovery_type: curator
  druid_serverview_type: http
  druid_coordinator_loadqueuepeon_type: http
  # Prometheus Metrics
  druid_emitter: prometheus
  druid_emitter_prometheus_port: 9090
  druid_emitter_prometheus_strategy: exporter

# Coordinator
coordinator:
  replicaCount: 1
  resources:
    requests:
      cpu: 100m
      memory: 768Mi
    limits:
      cpu: 500m
      memory: 1536Mi
  persistence:
    enabled: true
    storageClass: rook-ceph-block-enterprise
    size: 5Gi
  envVars:
    DRUID_XMX: 512m
    DRUID_XMS: 512m
    DRUID_MAXDIRECTMEMORYSIZE: 200m
    druid_coordinator_asOverlord_enabled: "true"
    druid_coordinator_asOverlord_overlordService: druid/overlord
  extraEnvFrom:
    - secretRef:
        name: druid-deep-storage

# Broker
broker:
  replicaCount: 1
  resources:
    requests:
      cpu: 100m
      memory: 768Mi
    limits:
      cpu: 500m
      memory: 1536Mi
  envVars:
    DRUID_XMX: 384m
    DRUID_XMS: 384m
    DRUID_MAXDIRECTMEMORYSIZE: 400m
    druid_processing_buffer_sizeBytes: "50000000"
    druid_processing_numMergeBuffers: "2"
    druid_processing_numThreads: "1"
  extraEnvFrom:
    - secretRef:
        name: druid-deep-storage

# Historical
historical:
  tiers:
    default:
      envVars:
        DRUID_XMX: 384m
        DRUID_XMS: 384m
        DRUID_MAXDIRECTMEMORYSIZE: 400m
        druid_processing_buffer_sizeBytes: "50000000"
        druid_processing_numMergeBuffers: "2"
        druid_processing_numThreads: "1"
        druid_server_tier: "tier_default"
        druid_segmentCache_locations: '[{"path":"/opt/druid/var/druid/segment-cache","maxSize":"1GiB"}]'
      resources:
        requests:
          cpu: 100m
          memory: 768Mi
        limits:
          cpu: 500m
          memory: 1536Mi
      persistence:
        size: 10Gi
        storageClass: rook-ceph-block-enterprise
      extraEnvFrom:
        - secretRef:
            name: druid-deep-storage

# Indexer for Kafka ingestion tasks
indexer:
  enabled: true
  defaults:
    replicaCount: 1
    resources:
      requests:
        cpu: 200m
        memory: 2048Mi
      limits:
        cpu: 1500m
        memory: 4096Mi
    envVars:
      # MiddleManager JVM settings
      DRUID_XMX: 512m
      DRUID_XMS: 512m
      DRUID_MAXDIRECTMEMORYSIZE: 400m
      # Peon (forked task) JVM settings - reduced for 4 concurrent tasks
      druid_indexer_runner_javaOpts: "-server -Xms384m -Xmx384m -XX:MaxDirectMemorySize=384m -XX:+ExitOnOutOfMemoryError"
      # Task processing settings
      druid_indexer_fork_property_druid_processing_buffer_sizeBytes: "50000000"
      druid_indexer_fork_property_druid_processing_numMergeBuffers: "2"
      druid_indexer_fork_property_druid_processing_numThreads: "1"
      # Worker capacity - match number of supervisors
      druid_worker_capacity: "4"
    persistence:
      enabled: true
      storageClass: rook-ceph-block-enterprise
      size: 5Gi
    extraEnvFrom:
      - secretRef:
          name: druid-deep-storage

# Router (UI)
router:
  replicaCount: 1
  resources:
    requests:
      cpu: 50m
      memory: 256Mi
    limits:
      cpu: 250m
      memory: 512Mi
  envVars:
    DRUID_XMX: 128m
    DRUID_XMS: 128m
    DRUID_MAXDIRECTMEMORYSIZE: 100m
    druid_router_managementProxy_enabled: "true"
  extraEnvFrom:
    - secretRef:
        name: druid-deep-storage
