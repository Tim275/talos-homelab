apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

# ðŸ¤– Ollama - Self-Hosted LLM Inference Server
# Model: Phi-3 Medium (14B parameters, 7.9GB RAM)
# Purpose: HolmesGPT AI-powered Kubernetes troubleshooting

resources:
  - deployment.yaml

namespace: ai-inference

commonLabels:
  app.kubernetes.io/name: ollama
  app.kubernetes.io/component: llm-inference
  app.kubernetes.io/part-of: ai-inference

commonAnnotations:
  argocd.argoproj.io/sync-wave: "5"
