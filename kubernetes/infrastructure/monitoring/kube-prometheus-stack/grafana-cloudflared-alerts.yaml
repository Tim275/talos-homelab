# ============================================================================
# GRAFANA & CLOUDFLARED ALERTS
# Enterprise Tier-0: Dashboard visibility and external access
# ============================================================================
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: grafana-cloudflared-alerts
  namespace: monitoring
  labels:
    prometheus: kube-prometheus-stack
    release: kube-prometheus-stack
    tier: observability
spec:
  groups:
    # ========================================================================
    # GRAFANA ALERTS
    # ========================================================================
    - name: grafana.high
      interval: 30s
      rules:
        # ====== P2: HIGH - Grafana Down ======
        - alert: GrafanaDown
          expr: |
            up{job="grafana"} == 0
          for: 5m
          labels:
            severity: warning
            priority: p2
            component: grafana
            tier: observability
            layer: observability
          annotations:
            summary: "Grafana is DOWN"
            description: |
              Grafana dashboard service is unreachable!
              NO DASHBOARD VISIBILITY!

              Duration: >5 minutes

              Impact: Cannot view dashboards, manual PromQL required
              Action: Check Grafana pod status

              Check: kubectl -n grafana get pods -l app.kubernetes.io/name=grafana

        # ====== P2: HIGH - Grafana High Memory ======
        - alert: GrafanaHighMemory
          expr: |
            container_memory_working_set_bytes{
              namespace="grafana",
              container="grafana"
            }
            / container_spec_memory_limit_bytes{
              namespace="grafana",
              container="grafana"
            } > 0.90
          for: 15m
          labels:
            severity: warning
            priority: p2
            component: grafana
            tier: observability
            layer: observability
          annotations:
            summary: "Grafana memory >90%"
            description: |
              Grafana is using {{ $value | humanizePercentage }} of memory limit.
              Risk of OOM and dashboard unavailability.

              Current: {{ $value | humanizePercentage }}
              Threshold: 90%

              Action: Increase memory limit or optimize dashboards

        # ====== P2: HIGH - Grafana Datasource Errors ======
        - alert: GrafanaDatasourceErrors
          expr: |
            increase(grafana_datasource_request_duration_seconds_count{status="error"}[5m]) > 10
          for: 10m
          labels:
            severity: warning
            priority: p2
            component: grafana
            tier: observability
            layer: observability
          annotations:
            summary: "Grafana datasource errors"
            description: |
              Grafana is experiencing errors querying datasources.
              Dashboards may show incomplete data.

              Datasource: {{ $labels.datasource }}
              Errors (5m): {{ $value }}

              Action: Check datasource connectivity

    - name: grafana.medium
      interval: 60s
      rules:
        # ====== P3: MEDIUM - Grafana Slow Queries ======
        - alert: GrafanaSlowQueries
          expr: |
            histogram_quantile(0.99,
              sum(rate(grafana_datasource_request_duration_seconds_bucket[5m])) by (le, datasource)
            ) > 10
          for: 15m
          labels:
            severity: info
            priority: p3
            component: grafana
            tier: observability
            layer: observability
          annotations:
            summary: "Grafana datasource queries slow (p99 >10s)"
            description: |
              Grafana queries to {{ $labels.datasource }} are slow.
              Dashboards may take long to load.

              Datasource: {{ $labels.datasource }}
              p99 Latency: {{ $value | printf "%.1f" }}s

    # ========================================================================
    # CLOUDFLARED TUNNEL ALERTS
    # ========================================================================
    - name: cloudflared.critical
      interval: 30s
      rules:
        # ====== P1: CRITICAL - Cloudflared Tunnel Down ======
        - alert: CloudflaredTunnelDown
          expr: |
            up{job="cloudflared"} == 0
          for: 3m
          labels:
            severity: critical
            priority: p1
            component: cloudflared
            tier: network
            layer: layer3
          annotations:
            summary: "Cloudflared tunnel is DOWN"
            description: |
              Cloudflared tunnel is unreachable!
              EXTERNAL ACCESS TO CLUSTER IS BROKEN!

              Duration: >3 minutes

              Impact: All external services unreachable from internet
              Team: @platform-oncall

              Check: kubectl -n cloudflared get pods

        # ====== P1: CRITICAL - Cloudflared All Replicas Down ======
        - alert: CloudflaredAllReplicasDown
          expr: |
            count(up{job="cloudflared"} == 1) == 0
          for: 2m
          labels:
            severity: critical
            priority: p1
            component: cloudflared
            tier: network
            layer: layer3
          annotations:
            summary: "All Cloudflared replicas are DOWN"
            description: |
              All Cloudflared tunnel replicas are down!
              COMPLETE EXTERNAL ACCESS FAILURE!

              Healthy Replicas: 0

              Impact: No external access to any service
              Team: @platform-oncall

    - name: cloudflared.high
      interval: 30s
      rules:
        # ====== P2: HIGH - Cloudflared Connection Errors ======
        - alert: CloudflaredConnectionErrors
          expr: |
            increase(cloudflared_tunnel_total_requests{status="error"}[5m]) > 50
          for: 10m
          labels:
            severity: warning
            priority: p2
            component: cloudflared
            tier: network
            layer: layer3
          annotations:
            summary: "Cloudflared tunnel connection errors"
            description: |
              Cloudflared is experiencing connection errors.
              External requests may fail!

              Error Count (5m): {{ $value }}
              Threshold: 50

              Action: Check tunnel status and Cloudflare dashboard

        # ====== P2: HIGH - Cloudflared High Latency ======
        - alert: CloudflaredHighLatency
          expr: |
            histogram_quantile(0.99,
              sum(rate(cloudflared_tunnel_request_duration_seconds_bucket[5m])) by (le)
            ) > 5
          for: 15m
          labels:
            severity: warning
            priority: p2
            component: cloudflared
            tier: network
            layer: layer3
          annotations:
            summary: "Cloudflared tunnel latency >5s (p99)"
            description: |
              Cloudflared tunnel requests are slow.
              External users experiencing high latency.

              p99 Latency: {{ $value | printf "%.1f" }}s
              Threshold: 5s

              Action: Check network connectivity and Cloudflare status

        # ====== P2: HIGH - Cloudflared Reconnections ======
        - alert: CloudflaredFrequentReconnections
          expr: |
            increase(cloudflared_tunnel_connections_total[5m]) > 10
          for: 10m
          labels:
            severity: warning
            priority: p2
            component: cloudflared
            tier: network
            layer: layer3
          annotations:
            summary: "Cloudflared frequent reconnections"
            description: |
              Cloudflared tunnel is reconnecting frequently.
              Connection stability issues!

              Reconnections (5m): {{ $value }}
              Threshold: 10

              Action: Check network stability and tunnel configuration
