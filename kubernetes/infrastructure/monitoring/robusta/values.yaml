# ‚öôÔ∏è ROBUSTA HELM VALUES - ENTERPRISE ALERT ENRICHMENT WITH AI
# ==============================================================
# StateLESS architecture = SealedSecrets compatible! 
# HolmesGPT with Ollama = Self-hosted AI, kostenlos! 

# CRITICAL: SealedSecrets Pattern
# Reference existing secret created separately
runner:
  # Enterprise resource limits
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 512Mi

  # SealedSecrets Compatible Pattern
  # Secret created separately, referenced here
  additional_env_vars:
    - name: SLACK_API_KEY
      valueFrom:
        secretKeyRef:
          name: robusta-slack-token
          key: api_key

# üì® Slack Integration (OAuth Bot Token)
sinksConfig:
  - slack_sink:
      name: homelab_slack
      api_key: "{{ env.SLACK_API_KEY }}"
      slack_channel: "#homelab-alerts"

# Global Configuration
clusterName: "timour-homelab-talos"  # REQUIRED by Robusta (TOP-LEVEL!)

globalConfig:
  # Prometheus Integration
  prometheus_url: "http://kube-prometheus-stack-prometheus.monitoring.svc:9090"
  alertmanager_url: "http://kube-prometheus-stack-alertmanager.monitoring.svc:9093"

#  Security Context
podSecurityContext:
  runAsNonRoot: true
  runAsUser: 1000
  fsGroup: 1000

# Monitoring
enablePrometheusStack: false  # We already have kube-prometheus-stack
enableServiceMonitors: true

# AI-POWERED DEBUGGING WITH HOLMESGPT + OLLAMA
# ================================================
# Self-hosted AI (kostenlos, privacy-first!)
# Uses local Ollama in ai-inference namespace
# Phi3:mini model (2.2GB, Microsoft, excellent for technical tasks)
enableHolmesGPT: true

holmesGPT:
  # Ollama endpoint (internal cluster service)
  apiUrl: "http://ollama.ai-inference.svc:11434/v1"

  # üß† Model: phi3:mini (Microsoft Phi-3)
  # Best for: Code analysis, technical reasoning, debugging
  model: "phi3:mini"

  # üîì No API key needed for self-hosted Ollama!
  # apiKey: ""  # Not required for Ollama

  # AI Configuration
  temperature: 0.2  # Lower = more focused, deterministic (good for debugging)
  maxTokens: 2048   # Enough for detailed analysis

  # ‚ö° Performance
  timeout: 60  # 60 seconds timeout for AI responses

# Playbooks
enablePlatformPlaybooks: true

# üé® AI Features Configuration
aiAnalysis:
  # Enable AI-powered root cause analysis
  enabled: true

  # Analyze these alert types with AI
  alertTypes:
    - "CrashLoopBackOff"
    - "OOMKilled"
    - "ImagePullBackOff"
    - "NodeNotReady"
    - "PodPending"
    - "DeploymentReplicasMismatch"

  # Add AI insights to Slack messages
  enrichSlackAlerts: true
