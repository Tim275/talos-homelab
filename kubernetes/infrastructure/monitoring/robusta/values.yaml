# yamllint disable rule:line-length
# Robusta - AI-Powered Kubernetes Monitoring
# https://github.com/robusta-dev/robusta

# ü§ñ Robusta + HolmesGPT - Enterprise Alert Enrichment
# AI-powered root cause analysis, alert correlation, and automatic remediation

# ========================================
# üîê CLUSTER CONFIGURATION
# ========================================
clusterName: "talos-homelab"

# ========================================
# üß† HOLMESGPT - AI INVESTIGATION ENGINE
# ========================================
enableHolmesGPT: true

holmesGPT:
  enableAiInvestigation: true

  # üîß AI Model Configuration
  # Ollama with Phi-3 Mini (self-hosted, CPU-only)
  # 3.8B parameters, 2.2GB, fast inference for alert analysis
  llm:
    model: "phi3:mini"    # Microsoft Phi-3 Mini (3.8B)
    provider: "openai"    # Ollama is OpenAI-compatible!
    api_url: "http://ollama.ai-inference.svc.cluster.local:11434"
    # No API key needed - runs locally!

  # üì¶ Resource Configuration
  resources:
    requests:
      cpu: 500m
      memory: 2048Mi  # HolmesGPT client (Ollama does the heavy lifting)
    limits:
      cpu: 2000m      # Allow burst for API calls
      memory: 4096Mi  # 4GB limit for prompt processing

  # üîß Toolsets Configuration
  toolsets:
    kubernetes/core:
      enabled: true
    kubernetes/logs:
      enabled: true
    robusta:
      enabled: true
    internet:
      enabled: true  # Allow web searches for error messages
    prometheus/metrics:
      enabled: true

# ========================================
# üèÉ ROBUSTA RUNNER - Alert Receiver
# ========================================
runner:
  # üì¶ Resources
  resources:
    requests:
      cpu: 250m
      memory: 1024Mi
    limits:
      cpu: 1000m
      memory: 2048Mi

  # üîê Service Account
  serviceAccount:
    create: true
    name: robusta-runner

  # üìä Metrics Exporter
  serviceMonitor:
    enabled: true
    path: /metrics

  # üåê Service Configuration
  service:
    type: ClusterIP
    annotations: {}

# ========================================
# üö® ALERTMANAGER INTEGRATION
# ========================================
# NOTE: We already have kube-prometheus-stack deployed
# We will configure AlertManager to send webhooks to Robusta
# via kube-prometheus-stack values (not here)
disableCloudRouting: false  # Keep cloud routing for Robusta UI (optional)

# ========================================
# üíæ PLAYBOOKS STORAGE
# ========================================
# Playbooks = Robusta's automation scripts
playbooksPersistentVolume: true
playbooksPersistentVolumeSize: 4Gi
playbooksPersistentVolumeStorageClass: "rook-ceph-block-enterprise"

# ========================================
# üîî SLACK INTEGRATION
# ========================================
# We already have Slack webhooks in AlertManager
# Robusta will send enriched alerts to same Slack channel
# TODO: Create sealed secret with Slack webhook

# ========================================
# üìä PROMETHEUS INTEGRATION
# ========================================
# Robusta needs Prometheus for:
# 1. Enriching alerts with metrics context
# 2. HolmesGPT metric analysis
prometheus:
  url: "http://kube-prometheus-stack-prometheus.monitoring.svc.cluster.local:9090"

# ========================================
# üéØ GRAFANA INTEGRATION (Optional)
# ========================================
# Robusta can auto-generate Grafana dashboard URLs
grafana:
  url: "https://grafana.timourhomelab.org"

# ========================================
# üêù ROBUSTA UI (Optional SaaS Platform)
# ========================================
# Robusta has optional SaaS platform for:
# - Alert timeline & correlation
# - Multi-cluster management
# - Advanced AI features
#
# For now: DISABLED (self-hosted only)
# Later: Optional signup at https://platform.robusta.dev
enablePlatformPlaybooks: false  # Don't send data to Robusta SaaS

# ========================================
# üìù CUSTOM PLAYBOOKS
# ========================================
# Playbooks = Robusta's automation rules
# Example: Auto-remediation, custom enrichment, etc.
customPlaybooks: []

# Active playbooks (default enrichments)
playbooksConfig:
  # üîç ALERT ENRICHMENT - Add context to every alert
  alert_enrichment:
    - on_prometheus_alert:
        include:
          - type: graph_enricher
            resource_type: Deployment
          - type: graph_enricher
            resource_type: DaemonSet
          - type: graph_enricher
            resource_type: StatefulSet
          - type: pod_events_enricher
          - type: pod_logs_enricher
            max_log_lines: 50
          - type: prometheus_enricher
            promql_query: "rate(container_cpu_usage_seconds_total[5m])"

  # ü§ñ HOLMESGPT INVESTIGATION - AI root cause analysis
  holmesgpt_investigation:
    - on_prometheus_alert:
        include:
          - type: holmes_investigation
            ask_holmes: true

# ========================================
# üì° SINKS CONFIGURATION
# ========================================
# Robusta enriches alerts with AI (HolmesGPT) and sends to Slack
# - #alerts: AI-enriched alerts with root cause analysis
# - #argocd-deployments: Deployment notifications

sinksConfig:
  # üîî Slack Sink - AI-Enriched Alerts
  # Sends AI-analyzed alerts to #alerts channel
  - slack_sink:
      name: robusta-slack-alerts
      slack_channel: alerts
      api_key:
        secretKeyRef:
          name: robusta-slack-webhook
          key: url

  # üìù Console Sink - Keep for debugging
  - file_sink:
      name: robusta-console-sink

# ========================================
# ü§ñ OLLAMA INTEGRATION
# ========================================
# HolmesGPT now uses self-hosted Ollama with Phi-3 Medium!
# Model: phi3:medium (14B parameters, 7.9GB RAM)
# Location: http://ollama.ai-inference:11434
# No API keys needed - fully self-hosted and private!
